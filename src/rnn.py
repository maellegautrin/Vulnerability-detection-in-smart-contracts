import numpy as np
from collections import OrderedDict
import scipy.special
from scipy.special import binom
import matplotlib.pyplot as plt
import time
import random
import re
import torch
import torch.nn as nn
import torch.nn.functional as F
import csv
import ast
import os
from sklearn.metrics import classification_report



use_gpu = torch.cuda.is_available()

def gpu(tensor, gpu=use_gpu):
    if gpu:
        return tensor.cuda()
    else:
        return tensor

def running_mean(x, N):
    cumsum = np.cumsum(np.insert(x, 0, 0))
    return (cumsum[N:] - cumsum[:-N]) / float(N)

nb_symbol= 128

class RecNet(nn.Module):
    def __init__(self, dim_input, dim_recurrent=1000, dim_output=2): #dim à modifier mais dim_recur >> dim_input pas bete
        super(RecNet, self).__init__()
        self.fc_x2h = nn.Linear(dim_input, dim_recurrent) # W_xh + b_h
        self.fc_h2h = nn.Linear(dim_recurrent, dim_recurrent, bias = False) # W_hh
        self.fc_h2y = nn.Linear(dim_recurrent, dim_output) # W_hy + b_y

    def forward(self, x):
        h = x.new_zeros(1, self.fc_h2y.weight.size(1)) #initialise h au format du hidden layer
        for t in range(x.size(0)):
            h = torch.relu(self.fc_x2h(x[t,:]) + self.fc_h2h(h)) #maj de h pour chaque input
        return self.fc_h2y(h) #sortie

RNN = gpu(RecNet(dim_input = nb_symbol))


cross_entropy = nn.CrossEntropyLoss()

learning_rate = 1e-4
optimizer = torch.optim.Adam(RNN.parameters(),lr=learning_rate)
loss_t = []
corrects =[]
labels = []

def extract_numbers(s):
    return [float(x) for x in re.findall(r'-?\d+\.?\d*', s)]

def extraire_matrice(fichier_path):
    with open(fichier_path, 'r') as file:
        data = file.read()
    numbers_list = extract_numbers(data)
    matrix = []
    row = []
    for num in numbers_list:
        row.append(num)
        if len(row) == 128:
            matrix.append(row)
            row = []
    return(matrix)

if __name__ == "__main__":
    train_files = os.listdir("train_rnn/")
    nb_train = len(train_files) #nb de graphs dans la phase d'entrainement
    random.shuffle(train_files)
    compter=0
    sum=0
    for f in train_files:
        print(compter, f)

        compter+=1
        if f.endswith('.txt') :
            matrice = extraire_matrice(os.path.join("train_rnn/",f))
            x = torch.tensor(matrice)
            l = torch.tensor([int(f[7])])
            l= l.to(torch.long)
    #at this point l is like tensor([1]) and x is like tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])
            y = RNN(x)
            loss = cross_entropy(y,l)
            _,preds = torch.max(y.data,1)
            if l.data.item()==preds.item():
                sum+=1
            print(preds.item() == l.data.item())
            print(sum/compter)
            corrects.append(preds.item() == l.data.item())
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            loss_t.append(loss)
            labels.append(l.data)

    plt.plot(running_mean([t.item() for t in loss_t],int(nb_train/100)))#montre l'évolution de la loss
    plt.show()
    plt.plot(running_mean(corrects,int(nb_train/100))) #montre l'évolution de l'"accuracy"
    plt.show()

    test_files = os.listdir("test_rnn/")
    nb_test = len(test_files) #nb de graphs dans la phase de test
    corrects = []
    true_positive = 0
    true_negative = 0
    false_positive = 0
    false_negative = 0
    y_true=[]
    y_pred = []
    random.shuffle(test_files)
    for f in test_files:
        if f.endswith('.txt') :
            matrice = extraire_matrice(os.path.join("test_rnn/",f))
            x = torch.tensor(matrice)
            l = torch.tensor([int(f[7])])
            l= l.to(torch.long)
            y = RNN(x)
            _, preds = torch.max(y.data, 1)
            corrects.append(preds.item() == l.data.item())
            y_true.append(l.data.item())
            y_pred.append(preds.item())
            if preds.item()==1 and l.data.item() ==1:
                true_positive+=1
            elif preds.item()==1 and l.data.item() ==0:
                false_positive+=1
            elif preds.item()==0 and l.data.item() ==1:
                false_negative+=1
            elif preds.item()==0 and l.data.item() ==0:
                true_negative+=1
    report = classification_report(y_true, y_pred)

    print("Classification Report:")
    print(report)
    print("accuracy rnn =",(true_positive+true_negative)/(true_positive+false_positive+true_negative+false_negative) )
    print("recall =", true_positive/(true_positive+false_negative) )
    print("precision =", true_positive/(true_positive+false_positive))
    print(false_positive) 
    print(false_negative)

